{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 2: Using Scikit-learn on Sentinel-2 Image Data\n",
    "---\n",
    "\n",
    "*Authors: [Joe Fennell](https://github.com/joe-fennell/), [Therese Cantwell](https://github.com/TMCantwell/), [Andr√©s Aguilar Ariza](https://github.com/anaguilarar/) & [Anna Scaife](https://github.com/as595/).*\n",
    "\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Objective:</b> You will use the k-means algorithm from the scikit-learn library to perform simple landcover classification on image data from the Sentinel-2 satellite.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "Before you start this tutorial, you should make sure that you are familiar with the material in [tutorial 1](https://github.com/darabigdata/AgriHack1/blob/master/TUTORIAL1/OpticalSatelliteImageryTutorial.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we're going to use both the [numpy]() and [matplotlib]() libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we're also going to import some functions from the [scikit-learn library]():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Loading the data:\n",
    "\n",
    "We'll load in the same dataset as before, but we're only going to store a subset of the image this time. We're selecting the pixel range [700:900, 300:500] from the full 1000 x 1000 image, and we'll put that in a numpy array called **im**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.load('data/S2_London.npy')[700:900,300:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Inspecting the data:\n",
    "\n",
    "To display what those data look like we need to perform the same [image histogram equalization](https://en.wikipedia.org/wiki/Histogram_equalization) that we did in [tutorial 1](https://github.com/darabigdata/AgriHack1/blob/master/TUTORIAL1/OpticalSatelliteImageryTutorial.ipynb), so let's repeat the function here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_histogram_equalization(image):\n",
    "    \n",
    "    \"\"\" \n",
    "    Function to perform image histogram equalisation.\n",
    "    \n",
    "    Method from: \n",
    "    http://www.janeriksolem.net/2009/06/histogram-equalization-with-python-and.html\n",
    "    \"\"\"\n",
    "    \n",
    "    # get histogram of data values using the numpy histogram function:\n",
    "    image_histogram, bins = np.histogram(image.flatten(), 256, density=True)\n",
    "    \n",
    "    # use this to make a cumulative distribution function:\n",
    "    cdf = image_histogram.cumsum() \n",
    "    \n",
    "    # normalise the CDF:\n",
    "    cdf = (255-1) * cdf / cdf[-1]\n",
    "\n",
    "    # use linear interpolation of the CDF to find new pixel values:\n",
    "    image_equalized = np.interp(image.flatten(), bins[:-1], cdf)\n",
    "    \n",
    "    if len(image.shape) == 3:\n",
    "        return image_equalized.reshape(image.shape).astype('uint8')[:,:,::-1]\n",
    "    else:\n",
    "        return image_equalized.reshape(image.shape).astype('uint8')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot up the resulting image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_equalized = image_histogram_equalization(im[:,:,:3])\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(im_equalized)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image shape = {s[0]} x {s[1]} x {s[2]}'.format(s=im.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Preparing the data:\n",
    "\n",
    "We can see that this is an m x n x 4 (4-band) image. To use the scikit-learn functions, the data must be in a 2-dimensional array where each row is a data sample (i.e. a spatial pixel) and each column is a feature value (i.e. channel brightness). \n",
    "\n",
    "Four our input image, **im**, there should be 200 x 200 = 40000 samples, each with 4 feature values (columns).\n",
    "\n",
    "So let's define a function that re-shapes our image into this format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_to_2d(arr):\n",
    "    \n",
    "    \"\"\" \n",
    "    Function to convert image array into list\n",
    "    \"\"\"\n",
    "    \n",
    "    s = arr.shape\n",
    "   \n",
    "    return np.ravel(arr).reshape((-1,s[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run this function on the input image, **im**. The output will be called **im_2d**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_2d = multi_to_2d(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can check that the re-shaping has worked by looking at the dimensions of the output array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of new array: \",im_2d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Using the data:\n",
    "\n",
    "Now we have the data in a format suitable for use with scikit-learn we can use the inbuilt [k-means clustering algorithm](https://en.wikipedia.org/wiki/K-means_clustering) to try out some simple [unsupervised machine learning](https://en.wikipedia.org/wiki/Unsupervised_learning) on our data.\n",
    "\n",
    "There are a couple of steps we need to go through:\n",
    "\n",
    "1. Pre-processing the data: there are different ways of scaling input data, here we are using the [scikit-learn robust_scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.robust_scale.html#sklearn.preprocessing.robust_scale) function. There is a comparison of different scaling methods [here](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html).\n",
    "\n",
    "2. Cluster the data: we first need to initiate the [scikit-learn KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) object. We are requesting that it look for 6 clusters - this is smaller than the default value of 8. We then need to use k-means to fit our input data using the <code>fit_predict</code> function, which will compute the cluster centers and predict a cluster index for each data sample (pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: robust scale the dataset:\n",
    "im_2d = preprocessing.robust_scale(im_2d)\n",
    "\n",
    "# step 2(a): construct a KMeans object:\n",
    "clus = cluster.KMeans(n_clusters=6)\n",
    "\n",
    "# step 2(b): perform the clustering computation:\n",
    "clusters = clus.fit_predict(im_2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise which pixels belong to each cluster, we can reshape the **clusters** data array to match the shape of the **im** array (only the first two dimensions of im):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusters.reshape(im.shape[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use matplotlib to display the resulting image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(clusters,'gist_rainbow')\n",
    "plt.title('Clusters')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The six clusters are indexed [0, 5], where cluster zero is displayed as red in the image and cluster five is displayed as magenta. The k-means algorithm is suggesting that these six clusters represent *six different types of landcover*, i.e. water, vegetation, buildings etc.\n",
    "\n",
    "* **Question:** How well do you think it did?\n",
    "* **Question:** Can you visualise the clusters? [This page](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html) might help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "That's the end of the tutorial. Now it's your turn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
